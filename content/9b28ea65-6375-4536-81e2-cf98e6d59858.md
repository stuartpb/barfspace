# The Engine

This is the idea behind the world of [The Easter Witch](6afe9432-b98b-4dc1-abda-c817ebf29c6f.md)

## Abstract

It started out with a very elaborate physical model, at least Dwarf-Fortress level.

But we never built an interface. We'd just describe our thoughts, and feed them into GPT-3

So we built a hybrid system, where one system models physics and the objective state of reality, and an outer level

Each "turn" was presented to the system as a hybrid document. You'd have it read the current "facts", give a bit of narrative to describe thoughts and speech, and then describe actions. The GPT system would use this to recognize what kind of narrative translated into what kind of "engine actions".

## alternative take on the origins of the two-phase system and implementation

this system's clever reason for being comes from how the problem with GPT-3 was that it has a kind of dreamlike floating focus and model / understanding of the world. You can say anything, and it will adjust its understanding of the world to flow from just the last thing you said: persistence of anything requires the Objective World model.

Further, and this is a thing I've had explained to me about RPGs: there's no play to not having to follow any rules in what you can and can't do. Shooting your gun three times longer than you can without having to reload, all that - it makes the writing turn lazy, focused on repeating the same problems to the same solutions. See Pierce in the D&D episode of Community saying "Unfreeze time! I rain so much fire down on you..." only to be told, no, unfreezing time takes a turn, and everyone else gets that window to attack him, and it's risky, but they make it. Not only do they help keep things from flying away logically, they also keep

This does raise the question of "but then what when the player's described actions contradict the objective reality?" but I guess that's just "the system translated your actions into representations, and then the Objective Server rejected them as invalid and/or nonsense"

what if the Subjective part is "Shem" and the Objective Judge is "Shaun"

So basically, the Objective World is translated into an immutable, rigidly-worded statement that is prepended to all actions before GPT-3 processes the "translate body of text into representative objective action abstraction objects" model.

but so anyway, this is presented from the point of view of a system that is now auto-simulating: describing the situation, letting GPT-3 handle the "story logic" of human decisions and flourishes, etc, all the stuff that drives actions, and then reiterating after seeing how what it said has affected the world, based on the kind of gameplay it was fed in during development.

## okay so this is a "real implementation" thought

you could have the "human description translated to actions" thing be auto-suggested, and trained on a model generated by a sliding window, to allow the API to drift - if you want to deprecate the way things worked two years ago, you stop feeding that engine
